{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web QA\n",
    "\n",
    "Steps:\n",
    " * Crawl the web and clean the text\n",
    " * Split the text into Crunks of max number of tokens\n",
    " * Embed all chunks\n",
    " * QA based on text\n",
    " * Test Case: an essay from FED website\n",
    "\n",
    "ðŸ“Œ Moreï¼šhttps://github.com/openai/openai-cookbook/blob/main/apps/web-crawl-q-and-a/web-qa.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crawl the web and clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawl the web\n",
    "\n",
    "def crawl(url):\n",
    "\n",
    "    # Get the text from the URL using BeautifulSoup\n",
    "    soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "    # Get the text but remove the tags\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
    "    if (\"You need to enable JavaScript to run this app.\" in text):\n",
    "        print(\"Unable to parse page \" + url + \" due to JavaScript being required\")\n",
    "                # Otherwise, write the text to the file in the text directory\n",
    "    \n",
    "    return text\n",
    "\n",
    "# clean the text\n",
    "def remove_newlines(text):\n",
    "    text = str(text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    text = text.replace('  ', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_raw = crawl(\"https://www.federalreservehistory.org/essays/recession-of-1981-82\")\n",
    "text_clean = remove_newlines(text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"     Recession of 1981â€“82 | Federal Reserve History        Ã—  Close  Skip top navigation                   Federal Reserve History        Overview Great Recession and After (2007â€“) Great Moderation (1982â€“2007) Great Inflation (1965â€“1982) After the Accord (1951â€“1965) WWII and After (1941â€“1951) Great Depression (1929â€“1941) Fedâ€™s Formative Years (1913â€“1929) Before the Fed (1791â€“1913) List all essays          Federal Reserve People        Current Fed leaders People by time period People by affiliation List all people          About the Fed        Introduction Structure of the Fed Purposes and functions Current Fed leaders Other Federal Reserve sites          Learning Fed History        Classroom resources About this site Our authors Related resources   Home >          Federal Reserve History >          Time Period: The Great Inflation >         Recession of 1981â€“82   Recession of 1981â€“82 July 1981â€“November 1982 Lasting from July 1981 to November 1982, this economic downturn was triggered by tight monetary policy in an effort to fight mounting inflation.       Unemployed Chicagoans line up to apply for insurance at the Bureau of Unemployment, 1981.\\xa0(Associated Press photo by Jim Bourdier)      \\r       by \\r Tim Sablik, Federal Reserve Bank of Richmond\\r \\r      Prior to the 2007-09 recession, the 1981-82 recession was the worst economic downturn in the United States since the Great Depression. Indeed, the nearly 11 percent unemployment rate reached late in 1982 remains the apex of the post-World War II era (Federal Reserve Bank of St. Louis). Unemployment during the 1981-82 recession was widespread, but manufacturing, construction, and the auto industries were particularly affected. Although goods producers accounted for only 30 percent of total employment at the time, they suffered 90 percent of job losses in 1982. Three-fourths of all job losses in the goods-producing sector were in manufacturing, and the residential construction industry and auto manufacturers ended the year with 22 percent and 24 percent unemployment, respectively (Urquhart and Hewson 1983, 4-7). The economy was already in weak shape coming into the downturn, as a recession in 1980 had left unemployment at about 7.5 percent. Both the 1980 and 1981-82 recessions were triggered by tight monetary policy in an effort to fight mounting inflation. During the 1960s and 1970s, economists and policymakers believed that they could lower unemployment through higher inflation, a tradeoff known as the Phillips Curve. In the 1970s, the Fed pursued what economists would call â€œstop-goâ€ monetary policy, which alternated between fighting high unemployment and high inflation. During the â€œgoâ€ periods, the Fed lowered interest rates to loosen the money supply and target lower unemployment. During the â€œstopâ€ periods, when inflation mounted, the Fed would raise interest rates to reduce inflationary pressure. However, the Phillips Curve tradeoff proved unstable in the long-run, as inflation and unemployment increased together in the mid-1970s. While unemployment trended down slightly by the end of the decade, inflation continued to rise, reaching 11 percent in June 1979 (Federal Reserve Bank of St. Louis). Paul Volcker was appointed chairman of the Fed in August 1979 in large part because of his anti-inflation views. He had previously served as president of the New York Fed and had dissented from Fed policies he regarded as contributing to inflation expectations. He felt strongly that mounting inflation should be the primary concern for the Fed: â€œIn terms of economic stability in the future, [inflation] is what is likely to give us the most problems and create the biggest recessionâ€ (FOMC transcript 1979, 16). He also believed that the Fed faced a credibility problem when it came to keeping inflation in check. During the previous decade, the Fed had demonstrated that it did not place much emphasis on maintaining low inflation, and public expectation of such continued behavior would make it increasingly difficult for the Fed to bring inflation down. â€œ[F]ailure to carry through now in the fight on inflation will only make any subsequent effort more difficult,â€ he remarked (Volcker 1981b). Chairman of the Federal Reserve Board of Governors Paul Volcker holds his head in his hand at a meeting in Washington, D.C.(Photo: Bettmann/Bettmann/Getty Images) Volcker shifted Fed policy to aggressively target the money supply rather than interest rates. He took this approach for two reasons. First, mounting inflation made it difficult to know which interest rates targets were appropriately tight. While the nominal rates the Fed targeted could be quite high, the real interest rates (that is, the effective interest rates after adjusting for inflation) could still be quite low due to the expectation of inflation. Second, the new policy was meant to signal to the public that the Fed was serious about low inflation. The expectation of low inflation was important, as current inflation is driven in part by expectations of future inflation. Volckerâ€™s first attempt to lower inflation and inflationary expectations proved insufficient. The credit-control program initiated in March 1980 by the Carter administration precipitated a sharp recession (Schreft 1990). As unemployment mounted, the Fed eased up, an action reminiscent of the â€œstop-goâ€ policies the public had come to expect. In late 1980 and early 1981, the Fed once again tightened the money supply, allowing the federal funds rate to approach 20 percent. Despite this, long-run interest rates continued to rise. The ten-year Treasury bond rate increased from about 11 percent in October 1980 to more than 15 percent a year later, possibly because the market believed the Fed would back down from its tight policy when unemployment rose (Goodfriend and King 2005). This time, however, Volcker was adamant that the Fed not back down: â€œWe have set our course to restrain growth in money and credit. We mean to stick with itâ€ (Volcker 1981a). The economy officially entered a recession in the third quarter of 1981, as high interest rates put pressure on sectors of the economy reliant on borrowing, like manufacturing and construction. Unemployment grew from 7.4 percent at the start of the recession to nearly 10 percent a year later. As the recession worsened, Volcker faced repeated calls from Congress to loosen monetary policy, but he maintained that failing to bring down long-run inflation expectations now would result in â€œmore serious economic circumstances over a much longer period of timeâ€ (Monetary Policy Report 1982, 67). Ultimately, this persistence paid off. By October 1982, inflation had fallen to 5 percent and long-run interest rates began to decline. The Fed allowed the federal funds rate to fall back to 9 percent, and unemployment declined quickly from the peak of nearly 11 percent at the end to 1982 to 8 percent one year later (Federal Reserve Bank of St. Louis; Goodfriend and King 2005). The threat of inflation was not completely gone, as the Fed would face a number of â€œinflation scaresâ€ throughout the 1980s. However, the commitment of Volcker and his successors to aggressively targeting price stability helped ensure that the double-digit inflation of the 1970s would not return.  Bibliography Goodfriend, Marvin, and Robert G. King. â€œThe Incredible Volcker Disinflation.â€ Journal of Monetary Economics 52, no. 5 (July 2005): 981-1015. Board of Governors of the Federal Reserve System. â€œTranscript, Federal Open Market Committee Meeting.â€ April 17, 1979. Federal Reserve Bank of St. Louis. â€œFederal Reserve Economic Data (FRED).â€ Accessed October 29, 2013. Federal Reserveâ€™s Second Monetary Policy Report for 1982, Hearings before the Committee on Banking, Housing, and Urban Affairs, United States Senate, 97th Cong. (July 1982). Schreft, Stacey L. â€œCredit Controls: 1980.â€ Federal Reserve Bank of Richmond Economic Review 76, no. 6 (November/December 1990): 25-55. Urquhart, Michael A., and Marillyn A. Hewson. â€œUnemployment Continued to Rise in 1982 as Recession Deepened.â€ Bureau of Labor Statistics Monthly Labor Review, February 1983. Volcker, Paul A., â€œDealing with Inflation: Obstacles and Opportunities,â€ Remarks at the Alfred M. Landon Lecture Series on Public Issues, Kansas State University, Manhattan, KS, April 15, 1981a, via FRASER. Volcker, Paul A., â€œNo Time for Backsliding,â€ Remarks to the National Press Club, Washington, DC, September 25, 1981, via FRASER.  Written as of November 22, 2013. See disclaimer.   Related Essays Volcker's Announcement of Anti-Inflation Measures The Great Inflation Full Employment and Balanced Growth Act of 1978 (Humphrey-Hawkins)  Related People  Paul A. Volcker                       Chairman                Board of Governors                1979 â€“ 1987           Federal Reserve History About Our Authors Terms of Use Privacy Policy Sitemap        Contact Us        @FedHistory     \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the text into Crunks of max number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "max_tokens = 500\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(text_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_many(text_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embed all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import openai\n",
    "from openai.embeddings_utils import distances_from_embeddings, cosine_similarity\n",
    "\n",
    "df = pd.DataFrame(chunks, columns=['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "\n",
    "# save for reuse\n",
    "#df.to_csv('embeddings.csv')\n",
    "#df=pd.read_csv('embeddings.csv', index_col=0)\n",
    "#df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recession of 1981â€“82 | Federal Reserve Hi...</td>\n",
       "      <td>497</td>\n",
       "      <td>[-0.034047387540340424, -0.017126478254795074,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both the 1980 and 1981-82 recessions were trig...</td>\n",
       "      <td>479</td>\n",
       "      <td>[-0.04432230070233345, -0.04187297821044922, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While the nominal rates the Fed targeted could...</td>\n",
       "      <td>496</td>\n",
       "      <td>[-0.05253702029585838, -0.03755616769194603, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_tokens  \\\n",
       "0       Recession of 1981â€“82 | Federal Reserve Hi...       497   \n",
       "1  Both the 1980 and 1981-82 recessions were trig...       479   \n",
       "2  While the nominal rates the Fed targeted could...       496   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.034047387540340424, -0.017126478254795074,...  \n",
       "1  [-0.04432230070233345, -0.04187297821044922, 0...  \n",
       "2  [-0.05253702029585838, -0.03755616769194603, 0...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    df,\n",
    "    model=\"text-davinci-003\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The 1980 and 1981-82 recessions were triggered by tight monetary policy in an effort to fight mounting inflation. \\n2. Paul Volcker was appointed chairman of the Fed in 1979 and shifted Fed policy to aggressively target the money supply rather than interest rates. \\n3. The credit-control program initiated in March 1980 by the Carter administration precipitated a sharp recession. \\n4. The Fed allowed the federal funds rate to approach 20 percent in late 1980 and early 1981. \\n5. Despite this, long-run interest rates continued to rise. \\n6. Volcker was adamant that the Fed not back down from its tight policy when unemployment rose. \\n7. By October 1982, inflation had fallen'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"What are the key takeways in the text? Summarize as points\", debug=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with FED website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_QA(url, question, debug=False):\n",
    "    \n",
    "    text_raw = crawl(url)\n",
    "    text_clean = remove_newlines(text_raw)\n",
    "    chunks = split_into_many(text_clean)\n",
    "    df = pd.DataFrame(chunks, columns=['text'])\n",
    "    df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "    df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "    \n",
    "    return answer_question(df, question=question, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The 1980 and 1981-82 recessions were triggered by tight monetary policy in an effort to fight mounting inflation. \\n2. Paul Volcker was appointed chairman of the Fed in 1979 and shifted Fed policy to aggressively target the money supply rather than interest rates. \\n3. The credit-control program initiated in March 1980 by the Carter administration precipitated a sharp recession. \\n4. The Fed allowed the federal funds rate to approach 20 percent in late 1980 and early 1981. \\n5. Despite this, long-run interest rates continued to rise. \\n6. Volcker was adamant that the Fed not back down from its tight policy when unemployment rose. \\n7. By October 1982, inflation had fallen'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FED_url = \"https://www.federalreservehistory.org/essays/recession-of-1981-82\"\n",
    "my_question  = \"What are the key takeways in the text? Summarize as points\"\n",
    "web_QA(FED_url, my_question, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
