{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get current dir\n",
    "dir = os.getcwd()\n",
    "file_path = dir + '/PDF/r230627b.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first page\n",
    "first_page = pages[0].page_content\n",
    "\n",
    "# concat all pages\n",
    "number_of_pages = len(pages)\n",
    "\n",
    "# concat all pages into a list\n",
    "all_pages = [pages[i].page_content for i in range(number_of_pages)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Chatbox\n",
    "with text length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "\n",
    "template = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferWindowMemory(k=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = pages[1].page_content\n",
    "# concat questions and text using f-strings\n",
    "first_question = f\"Based on the text, 1)list the top 5 most important topics in the text 2)list take aways briefly: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "Human: \n",
      "Based on the text, 1)list the top 5 most important topics in the text 2)list take aways briefly.\n",
      "\n",
      "AI: \n",
      "1) The top 5 most important topics in the text are: \n",
      "- OpenAI's language model, Assistant\n",
      "- Its capabilities and how it is constantly learning and improving\n",
      "- Its ability to process and understand large amounts of text\n",
      "- Its ability to generate human-like text\n",
      "- Its ability to engage in natural-sounding conversations\n",
      "\n",
      "2) Takeaways:\n",
      "- Assistant is a powerful language model trained by OpenAI\n",
      "- It is able to process and understand large amounts of text\n",
      "- It is able to generate human-like text and engage in natural-sounding conversations\n",
      "- It is constantly learning and improving, and its capabilities are constantly evolving\n",
      "- It can provide accurate and informative responses to a wide range of questions\n",
      "Human: Based on the text, 1)list the top 5 most important topics in the text 2)list take aways briefly: It is a pleasure to be with you here in Salzburg.1  Bank r egulators, particularly in the \n",
      "United States, have come to an inflection point where we are again taking stock of the reforms \n",
      "implemented after the 2008 financial crisis and evaluating whether these reforms have proven to \n",
      "be sufficient .  One justification for pushing these reviews forward has been the recent stress in \n",
      "the banking system .   \n",
      "The regulatory framework has evolved substantially since  the 2008 financial crisis.   The \n",
      "regulatory landscape has become more restrictive, with large in creases in capital and liquidity \n",
      "requirements, and other post -crisis reform s to improve bank resiliency.  S ince that time, the \n",
      "banking landscape has also evolved.  Today, to stay competitive, banks need to be able to \n",
      "quickly adopt new and innovative technology .   \n",
      "My remarks this afternoon will address  the importance of a responsive  and responsible \n",
      "regulatory framework, including regulation and supervision.  A responsive framework adapt s \n",
      "quickly to changing economic conditions, changing business activities a nd models, and emerging \n",
      "risks.  A responsible framework enables regulators to make changes that are informed by open \n",
      "debate and take into account intended and unintended consequences.  These two concepts —\n",
      "adapting to changing conditions, and transparency ab out regulatory adjustments —are \n",
      "intertwined .  They inform my view about how bank regulation should evolve and adapt over \n",
      "time.  This is particularly relevant now in light of the calls for reform of the regulatory \n",
      "framework, motivated in part by a  desire to remediate perceived weaknesses that contributed to  \n",
      "recent bank failures . \n",
      " \n",
      "1  The views expressed here are my own and not necessarily those of my colleagues on the Federal Open Market \n",
      "Committee or the Board of Governors.\n",
      "Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "1) The top 5 most important topics in the text are: \n",
      "- The 2008 financial crisis and the reforms implemented afterwards\n",
      "- The current stress in the banking system\n",
      "- The evolution of the regulatory framework\n",
      "- The importance of a responsive and responsible regulatory framework\n",
      "- Calls for reform of the regulatory framework\n",
      "\n",
      "2) Takeaways:\n",
      "- The regulatory framework has evolved substantially since the 2008 financial crisis\n",
      "- Banks need to be able to quickly adopt new and innovative technology to stay competitive\n",
      "- A responsive and responsible regulatory framework is necessary to adapt to changing economic conditions and emerging risks\n",
      "- Transparency about regulatory adjustments is important to inform regulatory changes\n",
      "- Calls for reform of the regulatory framework are motivated by a desire to remediate perceived weaknesses that contributed to recent bank failures.\n"
     ]
    }
   ],
   "source": [
    "output = chatgpt_chain.predict(human_input=first_question)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "Human: \n",
      "Based on the text, 1)list the top 5 most important topics in the text 2)list take aways briefly.\n",
      "\n",
      "AI: \n",
      "1) The top 5 most important topics in the text are: \n",
      "- OpenAI's language model, Assistant\n",
      "- Its capabilities and how it is constantly learning and improving\n",
      "- Its ability to process and understand large amounts of text\n",
      "- Its ability to generate human-like text\n",
      "- Its ability to engage in natural-sounding conversations\n",
      "\n",
      "2) Takeaways:\n",
      "- Assistant is a powerful language model trained by OpenAI\n",
      "- It is able to process and understand large amounts of text\n",
      "- It is able to generate human-like text and engage in natural-sounding conversations\n",
      "- It is constantly learning and improving, and its capabilities are constantly evolving\n",
      "- It can provide accurate and informative responses to a wide range of questions\n",
      "Human: Based on the text, 1)list the top 5 most important topics in the text 2)list take aways briefly: It is a pleasure to be with you here in Salzburg.1  Bank r egulators, particularly in the \n",
      "United States, have come to an inflection point where we are again taking stock of the reforms \n",
      "implemented after the 2008 financial crisis and evaluating whether these reforms have proven to \n",
      "be sufficient .  One justification for pushing these reviews forward has been the recent stress in \n",
      "the banking system .   \n",
      "The regulatory framework has evolved substantially since  the 2008 financial crisis.   The \n",
      "regulatory landscape has become more restrictive, with large in creases in capital and liquidity \n",
      "requirements, and other post -crisis reform s to improve bank resiliency.  S ince that time, the \n",
      "banking landscape has also evolved.  Today, to stay competitive, banks need to be able to \n",
      "quickly adopt new and innovative technology .   \n",
      "My remarks this afternoon will address  the importance of a responsive  and responsible \n",
      "regulatory framework, including regulation and supervision.  A responsive framework adapt s \n",
      "quickly to changing economic conditions, changing business activities a nd models, and emerging \n",
      "risks.  A responsible framework enables regulators to make changes that are informed by open \n",
      "debate and take into account intended and unintended consequences.  These two concepts —\n",
      "adapting to changing conditions, and transparency ab out regulatory adjustments —are \n",
      "intertwined .  They inform my view about how bank regulation should evolve and adapt over \n",
      "time.  This is particularly relevant now in light of the calls for reform of the regulatory \n",
      "framework, motivated in part by a  desire to remediate perceived weaknesses that contributed to  \n",
      "recent bank failures . \n",
      " \n",
      "1  The views expressed here are my own and not necessarily those of my colleagues on the Federal Open Market \n",
      "Committee or the Board of Governors.\n",
      "AI: \n",
      "1) The top 5 most important topics in the text are: \n",
      "- The 2008 financial crisis and the reforms implemented afterwards\n",
      "- The current stress in the banking system\n",
      "- The evolution of the regulatory framework\n",
      "- The importance of a responsive and responsible regulatory framework\n",
      "- Calls for reform of the regulatory framework\n",
      "\n",
      "2) Takeaways:\n",
      "- The regulatory framework has evolved substantially since the 2008 financial crisis\n",
      "- Banks need to be able to quickly adopt new and innovative technology to stay competitive\n",
      "- A responsive and responsible regulatory framework is necessary to adapt to changing economic conditions and emerging risks\n",
      "- Transparency about regulatory adjustments is important to inform regulatory changes\n",
      "- Calls for reform of the regulatory framework are motivated by a desire to remediate perceived weaknesses that contributed to recent bank failures.\n",
      "Human: \n",
      "what's the outlook for economic?\"\n",
      "\n",
      "Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "The outlook for the global economy is uncertain due to the ongoing COVID-19 pandemic. The International Monetary Fund (IMF) has projected that the global economy will contract by 4.9% in 2020, the worst economic downturn since the Great Depression. The IMF also projects that the global economy will recover in 2021, with a growth rate of 5.4%. However, this recovery is dependent on the successful containment of the virus and the implementation of effective economic policies.\n"
     ]
    }
   ],
   "source": [
    "output = chatgpt_chain.predict(human_input=\"\"\"\n",
    "what's the outlook of economic?\"\n",
    "\"\"\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. full text Q&A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text into chunks\n",
    "max_tokens = 500\n",
    "\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"text-davinci-003\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 load text and split into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all pages into string\n",
    "full_text = all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7956"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "len(tokenizer.encode(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_into_many(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(chunks, columns = ['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai.embeddings_utils import distances_from_embeddings,cosine_similarity\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"how is the weather?\", debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topic is responsible and responsive bank regulation and supervision.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"what's the topic?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
