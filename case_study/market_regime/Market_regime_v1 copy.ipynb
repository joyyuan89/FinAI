{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYVPd7AtoXN5"
      },
      "source": [
        "# Market Regime Modeling - v1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9mFvUPBohaK"
      },
      "source": [
        "https://lucid.app/lucidchart/1d1da6ad-2f5b-404e-a2e0-5fc09d555908/edit?view_items=sDP_6P2O9gUE&invitationId=inv_f6dfc2ff-a89c-4265-bff5-bedbb0340d49"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0aAqPJU34q3r"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#plot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly as plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1.Data Preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7V5gH0yK7U6x"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIAAIAh34KmV"
      },
      "outputs": [],
      "source": [
        "# variables\n",
        "\n",
        "base_index_name = \"XAU Curncy\" # Gold\n",
        "# Base_index = \"EUCRBRDT Index\" # Crude oil\n",
        "\n",
        "li_rolling_window = [\n",
        "    10, # 2W\n",
        "    21, # 1M\n",
        "    42, # 2M\n",
        "    65, # 3M\n",
        "    ]\n",
        "li_calculation_type = [\n",
        "    \"MA\",\n",
        "    \"STD\",\n",
        "    \"DIFF\",\n",
        "    ]\n",
        "\n",
        "start_date = None\n",
        "end_date = None"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NbJiCahOpHBa"
      },
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyDTfJyJmmge"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dir = os.getcwd()\n",
        "raw_data = pd.read_csv(os.path.join(dir,\"INPUT/index_data.csv\"))\n",
        "\n",
        "# Convert date to datetime format from 8/2/23 to 2023-08-02\n",
        "raw_data['Date'] = pd.to_datetime(raw_data['Date'], format='%d/%m/%y')\n",
        "raw_data.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing - remove error/outliers\n",
        "raw_data.dropna(axis='columns', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#sns.heatmap(raw_data.corr(),annot=False)\n",
        "# change color map, cmap = reversed blue red\n",
        "sns.heatmap(raw_data.corr(),annot=False,cmap='RdBu_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4EcZBOG3gwCl",
        "outputId": "980eb77b-5ba9-4961-a3f6-49da757ccec2"
      },
      "outputs": [],
      "source": [
        "ref_data = pd.read_csv(os.path.join(dir,'INPUT/index_set.csv'))\n",
        "df_index_set = ref_data[ref_data['group']==1][['set','index']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_index_set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8NxlanQ5pM7c"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeOa54_J6_we"
      },
      "outputs": [],
      "source": [
        "# raw_data: raw data, with index = Date\n",
        "\n",
        "def preprocessing_scaler(raw_data, base_index):\n",
        "    scaled_data = raw_data.div(raw_data.iloc[0], axis=1) # Divide by the first row to normalize the starting point to 1\n",
        "    scaled_data = scaled_data.div(scaled_data.loc[:, base_index], axis=0) # Divide by Base price to neutralize the effect of inflation\n",
        "    \n",
        "    return scaled_data\n",
        "\n",
        "def select_period(raw_data, start_date, end_date):\n",
        "\n",
        "    #sort by date\n",
        "    raw_data = raw_data.sort_index()\n",
        "\n",
        "    if start_date == None:\n",
        "        start_date = raw_data.index[0]\n",
        "    if end_date == None:\n",
        "        end_date = raw_data.index[-1]\n",
        "   \n",
        "    return raw_data.loc[start_date:end_date]\n",
        "\n",
        "def group_data(raw_data,df_index_set):\n",
        "\n",
        "    # select columns from raw data where column name is in index set['index']\n",
        "    df_selected = raw_data[df_index_set['index']]\n",
        "\n",
        "    # caculate the mean value of columns if columns are in the same set\n",
        "    li_set = df_index_set['set'].unique()\n",
        "    for set in li_set:\n",
        "        df_selected[set] = df_selected[df_index_set[df_index_set['set'] == set]['index']].mean(axis=1)\n",
        "    \n",
        "    df_grouped = df_selected[li_set]\n",
        "\n",
        "    return df_grouped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3ZCThO43Rjd"
      },
      "outputs": [],
      "source": [
        "def round_to_n_levels(values,n): # round values into n levels from 0 to 1\n",
        "\n",
        "    values = (values-values.min())/(values.max()- values.min()) # normalize\n",
        "    values = (values * n).round(0) / n # round to n levels\n",
        "    return values\n",
        "\n",
        "def construct_market_data(df_raw, li_rolling_window, li_calculation_type,rounded = True, round_level = 8):\n",
        "    df_derived = pd.DataFrame()  # Create an empty DataFrame to store derived values\n",
        "\n",
        "    for col in df_raw.columns:\n",
        "        for rolling_window in li_rolling_window:\n",
        "            col_data = df_raw[col]  # Extract the column data to improve readability\n",
        "\n",
        "            if \"MA\" in li_calculation_type:\n",
        "                ma_col_name = f'{col}_MA{rolling_window}'\n",
        "                ma_values = col_data - col_data.rolling(window=rolling_window).mean()\n",
        "                df_derived[ma_col_name] = (ma_values > 0).astype(int)  # Convert boolean to 0 or 1\n",
        "\n",
        "            if \"STD\" in li_calculation_type:\n",
        "                std_col_name = f'{col}_STD{rolling_window}'\n",
        "                std_values = col_data.rolling(window=rolling_window).std() / col_data.rolling(window=rolling_window).mean()\n",
        "                if rounded:\n",
        "                    df_derived[std_col_name] = round_to_n_levels(values = std_values,n =round_level)\n",
        "                \n",
        "\n",
        "            if \"DIFF\" in li_calculation_type:\n",
        "                diff_col_name = f'{col}_DIFF{rolling_window}'\n",
        "                diff_values = col_data.diff(rolling_window)\n",
        "                df_derived[diff_col_name] = (diff_values > 0).astype(int)  # Convert boolean to 0 or 1\n",
        "\n",
        "    # Drop rows with missing values\n",
        "    df_derived.dropna(axis=0, how='any', inplace=True)\n",
        "\n",
        "    return df_derived\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ignore warining\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df_scaled = preprocessing_scaler(raw_data, base_index)\n",
        "df_period = select_period(df_scaled,start_date,end_date)\n",
        "df_grouped = group_data(df_period,df_index_set)\n",
        "df_derived = construct_market_data(df_grouped,li_rolling_window,li_calculation_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_derived.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data download\n",
        "df_derived.to_csv(os.path.join(dir,'INPUT/market_data.csv'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Data Analyisis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load processed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load data\n",
        "dir = os.getcwd()\n",
        "df_derived = pd.read_csv(os.path.join(dir,'INPUT/market_data.csv'), index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "market_data_PCA = df_derived.copy()\n",
        "#select columns that do NOT start with 'US_equity_AMZN'\n",
        "market_data = df_derived.loc[:,~df_derived.columns.str.startswith('US_equity_AMZN')]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mpz2EP-2QIe7"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ8q7TSjQJuF",
        "outputId": "c5d042c8-b855-4bae-fd35-a867b3d51a19"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "market_data_transformed = StandardScaler().fit_transform(market_data_PCA)\n",
        "pca = PCA()\n",
        "principalComponents = pca.fit_transform(market_data_transformed)\n",
        "\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns=market_data_PCA.columns)\n",
        "Ranking_PC0 = abs(principalDf.iloc[0,:])\n",
        "Ranking_PC0.sort_values(ascending=False, inplace=True)\n",
        "\n",
        "Ranking_PC1 = abs(principalDf.iloc[1,:])\n",
        "Ranking_PC1.sort_values(ascending=False, inplace=True)\n",
        "\n",
        "print('PC0 ranking')\n",
        "print(Ranking_PC0[:10])\n",
        "print()\n",
        "\n",
        "\n",
        "print('PC1 ranking')\n",
        "print(Ranking_PC1[:10])\n",
        "print()\n",
        "pca.explained_variance_ratio_.round(2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KIetO4NFpNEg"
      },
      "source": [
        "# 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import HighDimensionalClustering\n",
        "umap_kmeans = HighDimensionalClustering(reducer_name = 'UMAP', dimension= 2, Nneighbor=30, clustering_model_name = 'kMeans', Ncluster = 9)\n",
        "umap_kmeans.clustering(market_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x-Xglc2Lh-mz"
      },
      "outputs": [],
      "source": [
        "# add labels to the data\n",
        "clusterable_embedding = umap_kmeans.low_dimension_embedding\n",
        "labels = umap_kmeans.labels\n",
        "df_labeled = market_data.copy()\n",
        "df_labeled['label'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9E8MaUCWZJX"
      },
      "outputs": [],
      "source": [
        "# rename the labels by statistics of each cluster\n",
        "\n",
        "def rename_labels(df_labeled, relabel_col):\n",
        "\n",
        "    # rename lablels: rank of mean of US_equity_MA65 in each kmeans cluster(label) \n",
        "    df_summary = df_labeled.groupby(\"label\")[relabel_col].describe()\n",
        "    #df_summary['relabel'] = df_summary['mean'].rank(ascending= False).astype(int)\n",
        "    df_summary['relabel'] = df_summary['mean'].rank().astype(int)\n",
        "\n",
        "    # add column 'relabel' to df_labeled, keep the index of df_labeled\n",
        "    df_relabeled = df_labeled.join(df_summary['relabel'], on = 'label')\n",
        "\n",
        "    return df_relabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_relabeled = rename_labels(df_labeled, \"US_equity_MA65\")\n",
        "df_relabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate summary statistics for \"US_equity_MA65\" grouped by \"ranking\"\n",
        "df_relabeled.groupby(\"relabel\")[\"US_equity_MA65\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y3DAkoX7lCF"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qlLXY894e7jg"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'clusterable_embedding' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/q_/2syhc8zd0bzd52v4kv8xp4g80000gq/T/ipykernel_71921/2348492069.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeansVisualizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeansVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterable_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_relabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clusterable_embedding' is not defined"
          ]
        }
      ],
      "source": [
        "from visualizer import KMeansVisualizer\n",
        "visualizer = KMeansVisualizer(clusterable_embedding, labels = np.array(df_relabeled['relabel']))\n",
        "visualizer.plot_2d()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "04A5IH_6eBS-",
        "outputId": "4966e819-07b6-4f66-de07-1a67e4fa9402"
      },
      "outputs": [],
      "source": [
        "# plot the time series of \"relabel\" of df_labled\n",
        "plt.plot(df_labeled[['relabel']].tail(500).reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUnSufkONmEK"
      },
      "source": [
        "# Prediction and Evaluation - Naive Bayes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "class sklearn.naive_bayes.CategoricalNB(*, alpha=1.0, force_alpha='warn', fit_prior=True, class_prior=None, min_categories=None)[source]Â¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BoleFT1q9ud"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_model = CategoricalNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1zu5McOq5ME"
      },
      "outputs": [],
      "source": [
        "def build_dataset(relabels, window_period):\n",
        "\n",
        "    Transition_table = pd.DataFrame(relabels, columns=['T']) # create a column T as Today's label\n",
        "    Transition_table['Last_median_03'] = Transition_table['T'].shift(1).rolling(window=3).median() # compute the median of the previous 3 days\n",
        "    Transition_table['Last_median_10'] = Transition_table['T'].shift(1).rolling(window=10).median() # compute the median of the previous 10 days\n",
        "    Transition_table['Last_median_'+str(window_period)] = Transition_table['T'].shift(1).rolling(window=window_period).median() # compute the median of the previous window period\n",
        "    # Transition_table['Last_mean_'+str(window_period)] = Transition_table['T'].shift(1).rolling(window=window_period).mean().round(0) # compute the mean of the previous window period\n",
        "    Transition_table['Last_max_'+str(window_period)] = Transition_table['T'].shift(1).rolling(window=window_period).max() # compute the max of the previous window period\n",
        "    Transition_table['Last_min_'+str(window_period)] = Transition_table['T'].shift(1).rolling(window=window_period).min() # compute the min of the previous window period\n",
        "    dataset = Transition_table.iloc[window_period+1:,:] # remove NA rows\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def naive_bayes(dataset, nb_model, if_eval):\n",
        "    \n",
        "    X = dataset.drop(['T'], axis=1)\n",
        "    y = dataset['T']\n",
        "\n",
        "    Last_X = X.iloc[-1] # get today's value\n",
        "\n",
        "    if if_eval:\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "\n",
        "        nb_model.fit(X_train, y_train)\n",
        "        y_pred = nb_model.predict(X_test)\n",
        "        # predit the last day #predict_proba return: array-like of shape (n_samples, n_classes)\n",
        "        last_pred  = nb_model.predict_proba([Last_X]).round(2)[0] # make prediction\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    else:\n",
        "        nb_model.fit(X, y)\n",
        "        y_pred = nb_model.predict(X)\n",
        "        last_pred  = nb_model.predict_proba([Last_X]).round(2)[0] # make prediction\n",
        "        accuracy = None\n",
        "\n",
        "    return last_pred, y_pred, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "relabels = list(df_relabeled[\"relabel\"])\n",
        "dataset = build_dataset(relabels, 20)\n",
        "X = dataset.drop(['T'], axis=1)\n",
        "y = dataset['T']\n",
        "Last_X = X.iloc[-1] # get today's value\n",
        "nb_model.fit(X, y)\n",
        "y_pred = nb_model.predict(X)\n",
        "last_pred  = nb_model.predict_proba([Last_X]).round(2)[0] # make prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = np.array([0])\n",
        "test = np.add(last_pred, last_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(test/2).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZhCF234LoRX"
      },
      "outputs": [],
      "source": [
        "def display(df_labeled, relabel_col, monitor_period):\n",
        "\n",
        "    df_relabeled = rename_labels(df_labeled, relabel_col)\n",
        "    #mapping of labels and relabels\n",
        "    mapping = dict(zip(df_relabeled[\"label\"], df_relabeled[\"relabel\"]))\n",
        "\n",
        "\n",
        "    fig = px.area(\n",
        "        df_relabeled[-monitor_period:],\n",
        "        x=df_relabeled[-monitor_period:].index,\n",
        "        y=df_relabeled[-monitor_period:][\"relabel\"],\n",
        "        labels=dict(x=\"Date\", y=\"Cycle Stage\"),\n",
        "        title=relabel_col,\n",
        "        height=350, width=500,\n",
        "        )\n",
        "    \n",
        "    fig.show()\n",
        "\n",
        "    relabels = list(df_relabeled[\"relabel\"])\n",
        "\n",
        "    # Bayes model probability\n",
        "    window_list = [i for i in range(20, 500) if i % 10 == 0]\n",
        "    res = np.array([0])\n",
        "\n",
        "    for window_period in window_list:\n",
        "\n",
        "        dataset = build_dataset(relabels, window_period)\n",
        "        res_i = naive_bayes(dataset, nb_model, if_eval = False)[0] # the list of probability for each culster\n",
        "        res = np.add(res_i, res)\n",
        "    \n",
        "    n = len(window_list)\n",
        "    res = (res/n).round(3)  # avarage probability for each culster\n",
        "    res = pd.DataFrame(res)\n",
        "\n",
        "    fig = px.bar(\n",
        "        res,\n",
        "        height=300, width=500,\n",
        "        text_auto=True,\n",
        "        )\n",
        "    \n",
        "    fig.show()\n",
        "\n",
        "    # statistics of each cluster\n",
        "    summary_table = df_relabeled.groupby(\"relabel\")[relabel_col].describe()\n",
        "    print(summary_table.round(2)) # mean column is the chance of market rally\n",
        "\n",
        "    # summary\n",
        "    summary_table['Chance'] = res\n",
        "    summary_table['Equity_rally_odds'] = summary_table['mean'] * summary_table['Chance']\n",
        "    summary_table['Equity_rally_STD'] = summary_table['std'] * summary_table['Chance']\n",
        "    Mean = summary_table.Equity_rally_odds.sum().round(3)\n",
        "    Std = summary_table.Equity_rally_STD.sum().round(3)\n",
        "    \n",
        "    print()\n",
        "    print(mapping)\n",
        "\n",
        "    print('Chance of rally in '+ relabel_col)\n",
        "    print(Mean)\n",
        "    print('Standard deviation')\n",
        "    print(Std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select all column names ending with _MA21\n",
        "col_list = df_labeled.columns[df_labeled.columns.str.endswith('_MA21')]\n",
        "monitor_period = 600\n",
        "col_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqa2vCxnpty4"
      },
      "source": [
        "# Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "so_hKDH5pTKm",
        "outputId": "48c9f43d-8503-4453-f637-00199df2be9d"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "for relabel_col in col_list:\n",
        "\n",
        "    display(df_labeled,relabel_col, monitor_period)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SYVPd7AtoXN5",
        "8NxlanQ5pM7c",
        "hGTqwC-FhBDc",
        "mpz2EP-2QIe7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
